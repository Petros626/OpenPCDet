{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1 bev labels: Use Complex-YOLOv4 source code (bev labels don't align 100% correct)\n",
    "# I guess the function map_pc2rc from bev_utils.py could bring here progress. The mapping must be in row. column format.\n",
    "# https://github.com/maudzung/Complex-YOLOv4-Pytorch/blob/master/src/data_process/kitti_bev_utils.py#L164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "boundary = {\n",
    "    \"minX\": 0,\n",
    "    \"maxX\": 60,\n",
    "    \"minY\": -30,\n",
    "    \"maxY\": 30,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "colors = [\n",
    "    [0, 0, 0],     # Dummy\n",
    "    [0, 0, 255], # Car\n",
    "    [255, 0, ],   # Pedestrian\n",
    "    [0, 255, 255]    # Cyclist\n",
    "]\n",
    "\n",
    "BEV_WIDTH = 640  # across y axis -25m ~ 25m\n",
    "BEV_HEIGHT = 640 # across x axis 0m ~ 50m\n",
    "\n",
    "label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/data_test_pipeline/kitti_train_dataset.pkl'\n",
    "# Load gt_boxes (lidar frame)\n",
    "with open(label_lidar_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# GT-Boxe\n",
    "#gt_boxes = data[0][0]['gt_boxes'] # sample: 000000\n",
    "#gt_boxes = data[1][0]['gt_boxes'] # 000003\n",
    "#gt_boxes = data[2][0]['gt_boxes'] # 000007\n",
    "#gt_boxes = data[3][0]['gt_boxes'] # 000009\n",
    "gt_boxes = data[4][0]['gt_boxes'] # 0000010\n",
    "# x, y, z, l, w, h, heading, class_idx\n",
    "print('OpenPCDet format (x,y,z,l,w,h,heading,class_dx): \\n', gt_boxes)\n",
    "print('\\n')\n",
    "\n",
    "complex_order = [7, 0, 1, 2, 5, 4, 3, 6]\n",
    "gt_boxes_reordered = gt_boxes[:, complex_order]\n",
    "\n",
    "# cls_id, x, y, z, h, w, l, yaw\n",
    "print('Complex-YOLO format (class_idx,x,y,z,h,w,l,yaw): \\n', gt_boxes_reordered)\n",
    "print('\\n')\n",
    "\n",
    "def build_yolo_target(labels):\n",
    "    bc = boundary\n",
    "    target = []\n",
    "    for i in range(labels.shape[0]):\n",
    "        cl, x, y, z, h, w, l, yaw = labels[i]\n",
    "        # ped and cyc labels are very small, so lets add some factor to height/width\n",
    "        #l = l + 0.3 # default\n",
    "        #w = w + 0.2 # default\n",
    "        yaw = np.pi * 2 - yaw  # default\n",
    "        if (bc[\"minX\"] < x < bc[\"maxX\"]) and (bc[\"minY\"] < y < bc[\"maxY\"]):\n",
    "            y1 = (y - bc[\"minY\"]) / (bc[\"maxY\"] - bc[\"minY\"])\n",
    "            x1 = (x - bc[\"minX\"]) / (bc[\"maxX\"] - bc[\"minX\"]) \n",
    "            w1 = w / (bc[\"maxY\"] - bc[\"minY\"])\n",
    "            l1 = l / (bc[\"maxX\"] - bc[\"minX\"])\n",
    "            target.append([cl, y1, x1, w1, l1, math.sin(float(yaw)), math.cos(float(yaw))])\n",
    "\n",
    "    return np.array(target, dtype=np.float32)\n",
    "\n",
    "target = build_yolo_target(gt_boxes_reordered)\n",
    "print('Build yolo target (class_idx,y,x,w,l,sin(y),cos(y)): \\n',target)\n",
    "print('\\n')\n",
    "print('Number of gt_boxes: ', len(target))\n",
    "\n",
    "def get_corners(x, y, w, l, yaw):\n",
    "    bev_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "    cos_yaw = np.cos(yaw)\n",
    "    sin_yaw = np.sin(yaw)\n",
    "    # front left\n",
    "    bev_corners[0, 0] = x - w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[0, 1] = y - w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    # rear left\n",
    "    bev_corners[1, 0] = x - w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[1, 1] = y - w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # rear right\n",
    "    bev_corners[2, 0] = x + w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[2, 1] = y + w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # front right\n",
    "    bev_corners[3, 0] = x + w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[3, 1] = y + w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    return bev_corners\n",
    "\n",
    "def drawRotatedBox(img, x, y, w, l, yaw, color):\n",
    "    bev_corners = get_corners(x, y, w, l, yaw)\n",
    "    corners_int = bev_corners.reshape(-1, 1, 2).astype(int)\n",
    "    cv2.polylines(img, [corners_int], True, color, 1)\n",
    "    corners_int = bev_corners.reshape(-1, 2).astype(int)\n",
    "    cv2.line(img, (corners_int[0, 0], corners_int[0, 1]), (corners_int[3, 0], corners_int[3, 1]), (255, 255, 0), 2)\n",
    "   \n",
    "def draw_box_in_bev(rgb_map, target):\n",
    "    for j in range(len(target)):\n",
    "        if (np.sum(target[j, 1:]) == 0): continue\n",
    "        cls_id = int(target[j][0])\n",
    "        x = target[j][1] * BEV_WIDTH\n",
    "        y = target[j][2] * BEV_HEIGHT\n",
    "        w = target[j][3] * BEV_WIDTH\n",
    "        l = target[j][4] * BEV_HEIGHT\n",
    "        yaw = np.arctan2(target[j][5], target[j][6])      \n",
    "        drawRotatedBox(rgb_map, x, y, w, l, yaw, colors[cls_id])\n",
    "\n",
    "# Test this code\n",
    "#bev_image = np.zeros((BEV_HEIGHT, BEV_WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "#bev_image = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000000.png')\n",
    "#bev_image = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000003.png')\n",
    "#bev_image = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000007.png')\n",
    "#bev_image = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000009.png')\n",
    "bev_image = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000010.png')\n",
    "\n",
    "bev_image = cv2.rotate(bev_image, cv2.ROTATE_180)\n",
    "draw_box_in_bev(bev_image, target)\n",
    "\n",
    "cv2.imshow(\"BEV\", bev_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 2 bev labels: Here also the mapping with rows, columns could help\n",
    "## Github repo: https://github.com/atanasko/ultralytics/blob/wod_obb_convert_dataset/wod_converter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "bev_width = 640\n",
    "bev_height = 640\n",
    "range_x = [0, 60]\n",
    "range_y = [-30, 30]\n",
    "\n",
    "def crop_bbox(x, y, size_x, size_y):\n",
    "    if x - size_x / 2 < 0:\n",
    "        if x < 0:\n",
    "            size_x = x + size_x / 2\n",
    "        if x > 0:\n",
    "            size_x = (size_x / 2 - x) + size_x / 2\n",
    "        x = size_x / 2\n",
    "    if x + size_x / 2 > bev_width:\n",
    "        if x < bev_width:\n",
    "            size_x = (bev_width - x) + size_x / 2\n",
    "        if x > bev_width:\n",
    "            size_x = size_x / 2 - (x - bev_width)\n",
    "        x = bev_width - size_x / 2\n",
    "    if y - size_y / 2 < 0:\n",
    "        if y < 0:\n",
    "            size_y = y + size_y / 2\n",
    "        if y > 0:\n",
    "            size_y = (size_y / 2 - y) + size_y / 2\n",
    "        y = size_y / 2\n",
    "    if y + size_y / 2 > bev_height:\n",
    "        if y < bev_height:\n",
    "            size_y = (bev_height - y) + size_y / 2\n",
    "        if y > bev_height:\n",
    "            size_y = size_y / 2 - (y - bev_height)\n",
    "        y = bev_height - size_y / 2\n",
    "\n",
    "    return x, y, size_x, size_y\n",
    "\n",
    "def rotate_point(x, y, cx, cy, theta):\n",
    "    # Rotate point (x, y) around center (cx, cy) by angle (in radians)\n",
    "    x_rel = x - cx\n",
    "    y_rel = y - cy\n",
    "    x_new = x_rel * math.cos(theta) - y_rel * math.sin(theta) + cx\n",
    "    y_new = x_rel * math.sin(theta) + y_rel * math.cos(theta) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "def calculate_rotated_bbox_coordinates(cx, cy, width, height, theta):\n",
    "    # Calculate the coordinates of the four corners of the rectangle\n",
    "    x1 = cx - width / 2\n",
    "    y1 = cy - height / 2\n",
    "    x2 = cx + width / 2\n",
    "    y2 = cy - height / 2\n",
    "    x3 = cx + width / 2\n",
    "    y3 = cy + height / 2\n",
    "    x4 = cx - width / 2\n",
    "    y4 = cy + height / 2\n",
    "\n",
    "    # Rotate the four corners around the center\n",
    "    x1_new, y1_new = rotate_point(x1, y1, cx, cy, theta)\n",
    "    x2_new, y2_new = rotate_point(x2, y2, cx, cy, theta)\n",
    "    x3_new, y3_new = rotate_point(x3, y3, cx, cy, theta)\n",
    "    x4_new, y4_new = rotate_point(x4, y4, cx, cy, theta)\n",
    "\n",
    "    return x1_new, y1_new, x2_new, y2_new, x3_new, y3_new, x4_new, y4_new\n",
    "\n",
    "def draw_bev_bbox(bev_img, x, y, l, w, yaw, color=(0, 255, 0), thickness=1):\n",
    "    # Without calculate_rotated_bbox_coordinates\n",
    "    # x1 = x - size_x / 2\n",
    "    # y1 = y - size_y / 2\n",
    "    # x2 = x + size_x / 2\n",
    "    # y2 = y - size_y / 2\n",
    "    # x3 = x + size_x / 2\n",
    "    # y3 = y + size_y / 2\n",
    "    # x4 = x - size_x / 2\n",
    "    # y4 = y + size_y / 2\n",
    "\n",
    "     # Rotieren um den Mittelpunkt (x, y)\n",
    "    # p1 = rotate_point(x1, y1, x, y, yaw)\n",
    "    # p2 = rotate_point(x2, y2, x, y, yaw)\n",
    "    # p3 = rotate_point(x3, y3, x, y, yaw)\n",
    "    # p4 = rotate_point(x4, y4, x, y, yaw)\n",
    "\n",
    "    # # Eckpunkte als Ganzzahlen umwandeln\n",
    "    # points = np.array([\n",
    "    #     [int(p1[0]), int(p1[1])],\n",
    "    #     [int(p2[0]), int(p2[1])],\n",
    "    #     [int(p3[0]), int(p3[1])],\n",
    "    #     [int(p4[0]), int(p4[1])]\n",
    "    # ], dtype=np.int32)\n",
    "\n",
    "    corners = calculate_rotated_bbox_coordinates(x, y, l, w, yaw)\n",
    "\n",
    "    points = np.array([[int(corners[0]), int(corners[1])],\n",
    "        [int(corners[2]), int(corners[3])],\n",
    "        [int(corners[4]), int(corners[5])],\n",
    "        [int(corners[6]), int(corners[7])]], dtype=np.int32)\n",
    "\n",
    "    # Polygon zeichnen\n",
    "    cv2.polylines(bev_img, [points], isClosed=True, color=color, thickness=thickness)\n",
    "\n",
    "    for point in points:\n",
    "        cv2.circle(bev_img, tuple(point), radius=2, color=(255, 0, 255), thickness=-1)\n",
    "\n",
    "\n",
    "# Incoming data must be ctr_x, ctr_y, ctr_z, size_x (l), size_y (w), size_z (h), heading\n",
    "# My KITTI data is ctr_x, ctr_y, ctr_z, l, w, h, heading, class_idx\n",
    "label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/data_test_pipeline/kitti_train_dataset.pkl'\n",
    "#bev_img = np.zeros((bev_height, bev_width, 3), dtype=np.uint8)\n",
    "bev_img = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000010.png')\n",
    "bev_img = cv2.rotate(bev_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "# Load gt_boxes (lidar frame)\n",
    "with open(label_lidar_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "sample_index = 4 # use this to change between 000000 - 000010\n",
    "gt_boxes = data[sample_index][0]['gt_boxes']\n",
    "frame = data[sample_index][0]['frame_id']\n",
    "print('frame_id: ', frame)\n",
    "print('Raw Bounding Boxes: ', gt_boxes)\n",
    "\n",
    "discrete = (range_x[1] - range_x[0]) / bev_width\n",
    "\n",
    "for box in gt_boxes:\n",
    "    x, y, l, w, yaw = box[0], box[1], box[3], box[4], box[6]\n",
    "    print('Extracted: ', x, y, l, w, yaw)\n",
    "\n",
    "    x = x / discrete\n",
    "    y = (-y / discrete) + bev_width / 2\n",
    "    l = l / discrete\n",
    "    w = w / discrete\n",
    "\n",
    "    x, y, l, w = crop_bbox(x, y, l, w)\n",
    "    print('Cropped for BEV image: ', x,y,l,w)\n",
    "\n",
    "    draw_bev_bbox(bev_img, x, y, l, w, -yaw, color=(0, 255, 0), thickness=1)\n",
    "\n",
    "cv2.imshow('BEV Bounding Box', bev_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 3 bev labels: BirdNet+: End-to-End 3D Object Detection in LiDAR Bird’s Eye View (works 100%)\n",
    "# https://github.com/AlejandroBarrera/birdnet2/blob/5ceed811b289796d7d7420a064ecb079c80801ab/tools/convert_kitti_to_coco_rotation.py#L73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from tools.visual_utils.bev_vis_utils import draw_bbox_arrow, draw_bbox_direction, draw_bbox_keypoint\n",
    "\n",
    "\n",
    "def get_bev_box_claudeai(x, y, l, w, yaw, bev_image, bvres):\n",
    "    bv_image = np.array(bev_image)\n",
    "    bvrows, bvcols, _ = bv_image.shape\n",
    "    \n",
    "    centroid = [x, y]\n",
    "    print('Centroid: ', centroid)\n",
    "   \n",
    "    # Ursprüngliche Ecken relativ zum Zentrum\n",
    "    corners = np.array([\n",
    "        [-l/2., w/2.],   # links oben\n",
    "        [l/2., w/2.],    # rechts oben\n",
    "        [l/2., -w/2.],   # rechts unten\n",
    "        [-l/2., -w/2.]   # links unten\n",
    "    ])\n",
    "    print('Ursprüngliche Corners (relativ zum Zentrum): \\n', corners)\n",
    "\n",
    "    # Rotationsmatrix\n",
    "    yaw = - yaw\n",
    "    c, s = np.cos(yaw), np.sin(yaw)\n",
    "    R = np.array([[c, -s], [s, c]])\n",
    "    print('Rotationsmatrix: \\n', R)\n",
    "\n",
    "    # Rotiere Corners um den Ursprung\n",
    "    rotated_corners = np.dot(corners, R)\n",
    "    print('Rotierte Corners (ohne Translation): \\n', rotated_corners)\n",
    "\n",
    "    # Verschiebe zurück zum Zentrum\n",
    "    rotated_corners += centroid\n",
    "    print('Rotierte Corners (mit Zentrum): \\n', rotated_corners)\n",
    "\n",
    "    # BEV-Koordinatentransformation\n",
    "    x1 = bvcols / 2 + (-rotated_corners[:, 1]) / bvres\n",
    "    y1 = bvrows - rotated_corners[:, 0] / bvres\n",
    "    \n",
    "    transformed_corners = np.column_stack((x1, y1))\n",
    "    print('Transformierte BEV-Corners: \\n', transformed_corners)\n",
    "\n",
    "    return transformed_corners\n",
    "   \n",
    "\n",
    "box_colormap = [\n",
    "    [255, 255, 255], # not assigned\n",
    "    [0, 255, 0], # Car Green\n",
    "    [255, 0, 255], # Pedestrian Violet\n",
    "    [0, 255, 255], # Cyclist Yellow\n",
    "]\n",
    "\n",
    "class_names = { \n",
    "    1: 'Car', \n",
    "    2: 'Ped',\n",
    "    3: 'Cyc'\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# DRAWS A ROTATED 2D-BOUNDING BOX ONTO A BEV IMAGE (BOX IN LiDAR FRAME REQUIRED)\n",
    "# ==============================================================================\n",
    "def get_rot_bevbox(x, y, l, w, yaw, cls, bev_img, bev_res=0.1):\n",
    "    \"\"\"\n",
    "    source: https://github.com/AlejandroBarrera/birdnet2\n",
    "    other worthwhile sources: https://github.com/maudzung/Complex-YOLOv4-Pytorch/blob/master/src/data_process/kitti_bev_utils.py, \n",
    "    https://github.com/spmallick/learnopencv/blob/master/3D-LiDAR-Object-Detection/sfa/data_process/kitti_bev_utils.py#L87\n",
    "    \"\"\"\n",
    "    # Convert BEV image to array and extract dimensions\n",
    "    bev_img = np.array(bev_img)\n",
    "    bvrows, bvcols, _ = bev_img.shape\n",
    "    # Define object's centroid, adjust rotation angle\n",
    "    centroid = [x, y]\n",
    "    \n",
    "    if cls == 1: # Car\n",
    "        # CAR\n",
    "        l = l + 0.4\n",
    "        w = w + 0.4\n",
    "    elif cls == 2: # Pedestrian\n",
    "        # https://github.com/maudzung/Complex-YOLOv4-Pytorch/blob/master/src/data_process/kitti_bev_utils.py\n",
    "        # PEDESTRIAN; Ped. and Cyc. labels are very small, so lets add some factor to height/width\n",
    "        l = l + 0.3\n",
    "        w = w + 0.3\n",
    "    elif cls == 3: # Cyclist\n",
    "        # CYCLIST\n",
    "        l = l + 0.3\n",
    "        w = w + 0.3\n",
    "\n",
    "    yaw = -yaw # Invert yaw from LiDAR frame to Image frame\n",
    "\n",
    "    # Calculate the initial coordinates of the object's four corners (relative to the centroid)\n",
    "    corners = np.array([[centroid[0] - l/2., centroid[1] + w/2.], # Top-left\n",
    "                        [centroid[0] + l/2., centroid[1] + w/2.], # Top-right\n",
    "                        [centroid[0] + l/2., centroid[1] - w/2.], # Bottom-right\n",
    "                        [centroid[0] - l/2., centroid[1] - w/2.]]) # Bottom-left\n",
    "\n",
    "    # Compute rotation matrix for yaw angle\n",
    "    cos, sin = np.cos(yaw), np.sin(yaw)\n",
    "    \"\"\"\n",
    "    2D-Rotation matrix\n",
    "    [x'] = [cos(yaw) -sin(yaw)] * [x]\n",
    "    [y']   [sin(yaw)  cos(yaw)]   [y]\n",
    "    \"\"\"\n",
    "    R = np.array([[cos, -sin], [sin, cos]])\n",
    "\n",
    "    # Rotate all corners around the centroid\n",
    "    rotated_corners = np.dot(corners-centroid, R) + centroid\n",
    "\n",
    "    # Convert the world coordinates to BEV image coordinates\n",
    "    x1, x2, x3, x4 = bvcols / 2 + (-rotated_corners[:, 1]) / bev_res  # world y -> image x (u)\n",
    "    y1, y2, y3, y4 = bvrows - rotated_corners[:, 0] / bev_res         # world x -> image y (v)\n",
    "\n",
    "    x1, x2, x3, x4 = x3, x4, x1, x2\n",
    "    y1, y2, y3, y4 = y3, y4, y1, y2\n",
    "    \n",
    "    # Remove bev labels for objects outside the BEV image\n",
    "    is_fully_visible = not (\n",
    "        (x1 < 0 or x1 >= bvcols) or\n",
    "        (x2 < 0 or x2 >= bvcols) or\n",
    "        (x3 < 0 or x3 >= bvcols) or\n",
    "        (x4 < 0 or x4 >= bvcols) or\n",
    "        (y1 < 0 or y1 >= bvrows) or\n",
    "        (y2 < 0 or y2 >= bvrows) or\n",
    "        (y3 < 0 or y3 >= bvrows) or\n",
    "        (y4 < 0 or y4 >= bvrows)\n",
    "    )\n",
    "    \n",
    "    # Calculate ROI of box\n",
    "    x_min = max(0, int(min(x1, x2, x3, x4)))\n",
    "    x_max = min(bvcols - 1, int(max(x1, x2, x3, x4)))\n",
    "    y_min = max(0, int(min(y1, y2, y3, y4)))\n",
    "    y_max = min(bvrows - 1, int(max(y1, y2, y3, y4)))\n",
    "\n",
    "    # Remove objects with fewer than 3 points in the box\n",
    "    roi = bev_img[y_min:y_max, x_min:x_max]\n",
    "    \"\"\"\n",
    "    (x1,y1)------(x2,y1)\n",
    "     |              |\n",
    "     |      ROI     |\n",
    "     |              |\n",
    "    (x1,y2)------(x2,y2)\n",
    "    \"\"\"\n",
    "    nonzero = np.count_nonzero(np.sum(roi, axis=2))\n",
    "    if nonzero < 3:  # Detection is considered unreliable with fewer than 3 points\n",
    "        return -1, -1, -1, -1\n",
    "   \n",
    "    if is_fully_visible:\n",
    "        return x1, y1, x2, y2, x3, y3, x4, y4, box_colormap[int(cls)], centroid \n",
    "        #return x1, x2, x3, x4, y1, y2, y3, y4, box_colormap[int(cls)], centroid # Return the coordinates of the four corners of the rotated bounding box in BEV image space\n",
    "    else:\n",
    "        return np.array([-1, -1, -1, -1]) # # Indicates the box should not be drawn (out of bounds)\n",
    "    \n",
    "\n",
    "def draw_lbl_and_score(image, class_name, conf_score=None, centroid = (0, 0), bev_res=0.1, color=(255, 255, 255), font_scale=0.5, thickness=1):\n",
    "    score = f'{conf_score:.2f}' if conf_score is not None else '-.--'\n",
    "\n",
    "    ctr_img_x = int(image.shape[1] / 2 + (-centroid[1]) / bev_res)  \n",
    "    ctr_img_y = int(image.shape[0] - centroid[0] / bev_res) \n",
    "\n",
    "    (lbl_width, lbl_height), _ = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_DUPLEX, font_scale, thickness)\n",
    "    (scr_width, scr_height), _ = cv2.getTextSize(score, cv2.FONT_HERSHEY_DUPLEX, font_scale, thickness)\n",
    "\n",
    "    c_x, c_y = ctr_img_x, ctr_img_y\n",
    "    lbl_x = int(c_x - lbl_width / 2) + 22  \n",
    "    lbl_y = int(c_y + lbl_height / 2) + 15 \n",
    "    lbl_x = max(0, min(lbl_x, image.shape[1] - lbl_width))\n",
    "    lbl_y = max(0, min(lbl_y, image.shape[0] - lbl_height))\n",
    "\n",
    "    scr_x = int(c_x + 38) \n",
    "    scr_y = int(c_y + 22)\n",
    "    scr_x = max(0, min(scr_x, image.shape[1] - scr_width))\n",
    "    scr_y = max(0, min(scr_y, image.shape[0] - scr_height))\n",
    "  \n",
    "    # Label\n",
    "    cv2.putText(image, class_name, (lbl_x, lbl_y), cv2.FONT_HERSHEY_DUPLEX, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    # Score\n",
    "    cv2.putText(image, str(score), (scr_x, scr_y), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255,255,255), thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def main (mode=str):\n",
    "\n",
    "    if mode == 'train':\n",
    "        #label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/data_test_pipeline/visualizer/kitti_train_dataset.pkl'\n",
    "        label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/kitti_train_dataset.pkl'\n",
    "        #bev_img = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/images for bev label test/bev_000000.png')\n",
    "        #bev_img = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/train/imgs/bev_000000_1.png')\n",
    "        bev_img = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/train/imgs/bev_000064_4.png')\n",
    "\n",
    "        with open(label_lidar_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        sample_index = 155 # use this to change between 000000 - 000010\n",
    "        augment_index = 4 # use this to change the augmentation\n",
    "        gt_boxes = data[sample_index][augment_index]['gt_boxes']\n",
    "\n",
    "    elif mode == 'val':\n",
    "        label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/data_test_pipeline/kitti_val_dataset.pkl'\n",
    "        bev_img = cv2.imread('/home/rlab10/OpenPCDet/lidar2bev/bev_images/val/imgs/bev_val_000001.png')\n",
    "\n",
    "        with open(label_lidar_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        sample_index = 0 # use this to change between 000001 - 000006\n",
    "        gt_boxes = data[sample_index]['annos']['gt_boxes_lidar']\n",
    "\n",
    "    bev_res = 0.1\n",
    "\n",
    "    for box in gt_boxes:\n",
    "    \n",
    "        x, y, l, w, yaw, cls = [box[i] for i in [0, 1, 3, 4, 6, 7]]\n",
    "\n",
    "        result = get_rot_bevbox(x, y, l, w, yaw, cls, bev_img, bev_res=bev_res)\n",
    "\n",
    "        if isinstance(result, np.ndarray) and np.any(result == -1):\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4, bbox_color, centroid  = result\n",
    "        polygon = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], dtype=np.int32).reshape((-1, 1, 2))\n",
    "        cv2.polylines(bev_img, [polygon], isClosed=True, color=bbox_color, thickness=1)\n",
    "\n",
    "        score = 0.94\n",
    "        draw_lbl_and_score(bev_img, class_names.get(cls, 'Unknown'), conf_score=score, centroid=centroid, color = bbox_color)\n",
    "\n",
    "\n",
    "        #for x, y in [(x1, y1)]:\n",
    "        #    cv2.circle(bev_img, (int(x), int(y)), radius=3, color=(0, 0, 255), thickness=-1)  # Red points\n",
    "      \n",
    "        #draw_bbox_direction(bev_img, np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]]))\n",
    "        #draw_bbox_arrow(bev_img, centroid=centroid, yaw=yaw, cls=cls, bev_res=bev_res, color=bbox_color)\n",
    "        #draw_bbox_keypoint(bev_img, centroid=centroid, cls=cls, bev_res=bev_res)\n",
    "        \n",
    "\n",
    "    cv2.imshow('BEV Image', bev_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main('train')\n",
    "    #main('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "label_lidar_path = '/home/rlab10/OpenPCDet/data/kitti/kitti_train_dataset.pkl'\n",
    "\n",
    "with open(label_lidar_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 4 bev labels: OpenPCDet intern functions (NOT TESTED)\n",
    "https://blog.csdn.net/W1995S/article/details/115486685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pcdet.ops.iou3d_nms.iou3d_nms_utils import boxes_iou3d_gpu\n",
    "from pcdet.utils.box_utils import boxes3d_nearest_bev_iou\n",
    "\n",
    "\n",
    "def assign_targets_single(self, anchors, gt_boxes, gt_classes, matched_threshold=0.6, unmatched_threshold=0.45):\n",
    "   num_anchors = anchors.shape[0]\n",
    "   num_gt = gt_boxes.shape[0]\n",
    "\n",
    "   labels = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n",
    "   gt_ids = torch.ones((num_anchors,), dtype=torch.int32, device=anchors.device) * -1\n",
    "\n",
    "   if len(gt_boxes) > 0 and anchors.shape[0] > 0:\n",
    "      anchor_by_gt_overlap = boxes_iou3d_gpu(anchors[:, 0:7], gt_boxes[:, 0:7]) \\\n",
    "        if self.match_height else boxes3d_nearest_bev_iou(anchors[:, 0:7], gt_boxes[:, 0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1 yolo obb health check: https://github.com/ultralytics/ultralytics/issues/13799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "bev_val_img = '/home/rlab10/OpenPCDet/lidar2bev/bev_images/val/imgs/bev_val_000006.png'\n",
    "bev_val_lbl = '/home/rlab10/OpenPCDet/lidar2bev/bev_images/val/labels/bev_val_000006.txt'\n",
    "\n",
    "bev_train_img = '/home/rlab10/OpenPCDet/lidar2bev/bev_images/train/imgs/bev_000003_4.png'\n",
    "bev_train_lbl = '/home/rlab10/OpenPCDet/lidar2bev/bev_images/train/labels/bev_000003_4.txt'\n",
    "\n",
    "\n",
    "def draw_obb(image_path, label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            cls, points = int(parts[0]), list(map(float, parts[1:9]))\n",
    "            points = [(int(points[i] * image.shape[1]), int(points[i+1] * image.shape[0])) for i in range(0, len(points), 2)]\n",
    "            points = np.array(points, np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(image, [points], isClosed=True, color=(0, 255, 0), thickness=1)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    #cv2.imshow('BEV Visualization', image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "#draw_obb(bev_val_img, bev_val_lbl)\n",
    "draw_obb(bev_train_img, bev_train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
