{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.datasets.kitti.kitti_dataset import *\n",
    "from pcdet.datasets.dataset import *\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from pathlib import Path\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "dataset_cfg = EasyDict(yaml.safe_load(open('/home/rlab10/OpenPCDet/tools/cfgs/dataset_configs/kitti_dataset.yaml')))\n",
    "class_names = ['Car', 'Pedestrian', 'Cyclist']\n",
    "file_path = '/home/rlab10/OpenPCDet/pcdet/datasets/kitti/kitti_dataset.py' \n",
    "ROOT_DIR = (Path(file_path).resolve().parent / '../../../').resolve()\n",
    "data_path = ROOT_DIR / 'data' / 'kitti'\n",
    "save_path = ROOT_DIR / 'data' / 'kitti'\n",
    "kitti_infos = []\n",
    "num_features = len(dataset_cfg.POINT_FEATURE_ENCODING.src_feature_list)\n",
    "\n",
    "def create_kitti_infos(dataset_cfg, class_names, data_path, save_path, workers=4):\n",
    "    from time import sleep\n",
    "    \n",
    "    dataset = KittiDataset(dataset_cfg=dataset_cfg, class_names=class_names, root_path=data_path, training=False, logger=common_utils.create_logger())\n",
    "    \n",
    "    train_split, val_split = 'train', 'val'\n",
    "    num_features = len(dataset_cfg.POINT_FEATURE_ENCODING.src_feature_list)\n",
    "\n",
    "    train_filename = save_path / ('kitti_infos_%s.pkl' % train_split)\n",
    "    val_filename = save_path / ('kitti_%s_dataset.pkl' % val_split)\n",
    "    test_filename = save_path / 'kitti_infos_test.pkl'\n",
    "\n",
    "    print('\\n' + '-' * 36 + 'Start to generate data infos' + '-' * 37)\n",
    "    print('---------------CAUTION: Source code is configured to serve as Augmentor NOT training-----------------')\n",
    "\n",
    "    dataset.set_split(train_split)\n",
    "    # ensure that get_infos() processes the single scene, NOTE: get_infos() collects infos about all classes (except 'DontCare'), filter unwanted classes with param `used_classes` in create_groundtruth_database.\n",
    "    kitti_infos_train = dataset.get_infos(num_workers=workers, has_label=True, count_inside_pts=True, num_features=num_features)\n",
    "    with open(train_filename, 'wb') as f:\n",
    "        pickle.dump(kitti_infos_train, f)\n",
    "    print('Kitti info train file is saved to %s\\n' % train_filename)\n",
    "    sleep(3)\n",
    "\n",
    "    dataset.set_split(val_split)\n",
    "    # ensure that mode 'test' will process the single scene with PointFeatureEncoder, DataProcessor, FOV_FLAG\n",
    "    dataset.training = False\n",
    "    allowed_classes = class_names\n",
    "    kitti_val_dataset = dataset.get_infos_val(num_workers=workers, has_label=True, count_inside_pts=True, num_features=num_features, class_names=allowed_classes)\n",
    "    with open(val_filename, 'wb') as f:\n",
    "        pickle.dump(kitti_val_dataset, f)\n",
    "    print('Kitti info val file is saved to %s\\n' % val_filename)\n",
    "    sleep(3)\n",
    "\n",
    "    dataset.set_split('test')\n",
    "    kitti_infos_test = dataset.get_infos(num_workers=workers, has_label=False, count_inside_pts=False)\n",
    "    with open(test_filename, 'wb') as f:\n",
    "       pickle.dump(kitti_infos_test, f)\n",
    "    print('Kitti info test file is saved to %s\\n' % test_filename)\n",
    "    sleep(3)\n",
    "\n",
    "    print('\\n---------------Start creating groundtruth database for later data augmentation-------------------------')\n",
    "    print('---------------CAUTION: Source code is configured to serve as Augmentor NOT training-------------------')\n",
    "    print('---------------No DataProcessor and PointFeatureEncoder required, handled by training data creation----')\n",
    "    \n",
    "    # Input the 'kitti_infos_train.pkl' to generate gt_database (cutted objects of samples)\n",
    "    dataset.set_split(train_split)\n",
    "    dataset.create_groundtruth_database(info_path=train_filename, used_classes=class_names, split=train_split)\n",
    "    print(f'---------------These groundtruth {train_split} objects are randomly inserted into samples (augmentation)-------')\n",
    "    print('-' * 41 + 'Data preparation Done' + '-' * 41)\n",
    "\n",
    "def save_data_list(data_list=None, save_path=None, root_path=None, sample_id_list=None, augmentors=None):\n",
    "    root_path = root_path if root_path is not None else Path(dataset_cfg.DATA_PATH) \n",
    "    split = dataset_cfg.DATA_SPLIT['train']\n",
    "    split_dir = root_path / 'ImageSets' / (split + '.txt')\n",
    "    sample_id_list = [x.strip() for x in open(split_dir).readlines()] if split_dir.exists() else None\n",
    "    \n",
    "    train_split = 'train'\n",
    "    train_filename = save_path / ('kitti_%s_dataset.pkl' % train_split)\n",
    "\n",
    "    aug_config_list = augmentors\n",
    "    num_features = len(dataset_cfg.POINT_FEATURE_ENCODING.src_feature_list)\n",
    "    \n",
    "    print('\\n' + '-' * 35 + 'Start to save data infos(original+augmented)' + '-' * 37)\n",
    "\n",
    "    with open(train_filename, 'wb') as f:\n",
    "        pickle.dump(data_list, f)\n",
    "    \n",
    "    for sample_idx in sample_id_list:\n",
    "        applied_augmentations = [str(name) for name in aug_config_list]\n",
    "        aug_str = ', '.join(applied_augmentations)\n",
    "        print(f\"{split} sample_idx: {sample_idx} (original, {aug_str})\")\n",
    " \n",
    "    print('Kitti info train/aug file is saved to %s' % train_filename)\n",
    "    print('-' * 49 + 'Data saving Done' + '-' * 51 + '\\n') \n",
    "\n",
    "\n",
    "# Step 1 : Create the data_infos, only validation data_infos and gt_database are important. \n",
    "# The val data get postprocessed through DataProcessor, PointFeatureEncoder, also includes only points of FOV.\n",
    "# The gt_database is necessary for successfully creating augmented training samples.\n",
    "create_kitti_infos(dataset_cfg, class_names, data_path, save_path, workers=4)\n",
    "\n",
    "# Step 2: Create the training set with data augmentation\n",
    "dataset = KittiDataset(dataset_cfg=dataset_cfg, class_names=class_names, root_path=data_path, training=True) # the training flag allows data augmentation before training\n",
    "\n",
    "# Step 3: Call the member method to catch information\n",
    "dataset.dataset_w_all_infos = dataset.get_infos(num_workers=4, has_label=True, count_inside_pts=True, num_features=num_features)\n",
    "\n",
    "\n",
    "# Cath the first entry of the dataset\n",
    "# TODO: How to split train and val, saving one in a list, the other in dict\n",
    "# Solution: let val as .pkl and use train+aug as .pkl too?\n",
    "#data_list = dataset[0].copy()\n",
    "#save_data_list_to_pkl(data_list=data_list, save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: save it\n",
    "dataset_as_list = []\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    data, applied_augmentors = dataset[idx]\n",
    "    # debug\n",
    "    #sample_idx = data[0]['frame_id']\n",
    "    #print(f\"{sample_idx}\")\n",
    "    dataset_as_list.append(data)   \n",
    "    # dataset_as_list.append(dataset[idx])\n",
    "\n",
    "save_data_list(data_list=dataset_as_list, save_path=save_path, root_path=None, sample_id_list=None, augmentors=applied_augmentors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test für eine 3D-BB in der Szene\n",
    "# first_sample = dataset[0][0]\n",
    "# gt_boxes = first_sample['gt_boxes']\n",
    "# points = first_sample['points']\n",
    "\n",
    "# print(\"GT Boxes:\", len(gt_boxes))\n",
    "# print(\"Points:\", len(points))\n",
    "\n",
    "# Test für mehrere 3D-BB in der Szene\n",
    "first_sample = dataset[2][0]\n",
    "gt_boxes = first_sample['gt_boxes']\n",
    "points = first_sample['points']\n",
    "\n",
    "print(\"GT Boxes:\", len(gt_boxes))\n",
    "print(\"GT Boxes Shape:\", gt_boxes.shape)\n",
    "print(\"Points:\", len(points))\n",
    "print(\"Points Shape:\", points.shape)\n",
    "\n",
    "# Test für mehrere 3D-BB in der Szene mit einer Kollision\n",
    "# first_sample = dataset[2][0]\n",
    "# gt_boxes = first_sample['gt_boxes'] = np.array([\n",
    "#     [25.299036, 0.70895809, -0.68842334, 3.2, 1.66, 1.61, 0.019203663, 1.0],  # Box 1\n",
    "#     [25.5, 0.8, -0.68842334, 3.2, 1.66, 1.61, 0.0, 1.0],                      # Box 2 (überlappt mit Box 1)\n",
    "#     [34.37772, 12.651429, -0.60237646, 1.95, 0.5, 1.72, -3.1107965, 3.0]      # Box 3 (keine Überlappung)\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "# points = first_sample['points']\n",
    "\n",
    "# print(\"GT Boxes:\", len(gt_boxes))\n",
    "# print(\"GT Boxes Shape:\", gt_boxes.shape)\n",
    "# print(\"Points:\", len(points))\n",
    "# print(\"Points Shape:\", points.shape)\n",
    "\n",
    "# Test für mehrere 3D-BB in der Szene mit mehreren Kollisionen\n",
    "# first_sample = dataset[2][0]\n",
    "# gt_boxes = first_sample['gt_boxes'] = np.array([\n",
    "#     # Box 1\n",
    "#     [25.299036, 0.70895809, -0.68842334, 3.2, 1.66, 1.61, 0.019203663, 1.0],  # Box 1\n",
    "#     [25.5, 0.8, -0.68842334, 3.2, 1.66, 1.61, 0.0, 1.0],                      # Box 2 (überlappt mit Box 1)\n",
    "#     [34.0, 12.0, -0.6, 1.5, 0.5, 1.7, -3.0, 1.0],                             # Box 3 (überlappt mit Box 4)\n",
    "#     [34.1, 12.1, -0.6, 1.5, 0.5, 1.7, -3.1, 1.0],                             # Box 4 (überlappt mit Box 3)\n",
    "#     [40.0, 15.0, -0.5, 2.0, 0.5, 1.5, 0.0, 1.0]                               # Box 5 (keine Überlappung)\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "# points = first_sample['points']\n",
    "\n",
    "# print(\"GT Boxes:\", len(gt_boxes))\n",
    "# print(\"GT Boxes Shape:\", gt_boxes.shape)\n",
    "# print(\"Points:\", len(points))\n",
    "# print(\"Points Shape:\", points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "from pcdet.ops.iou3d_nms.iou3d_nms_utils import *\n",
    "from pcdet.datasets.augmentor.augmentor_utils import *\n",
    "from pcdet.datasets.augmentor import augmentor_utils\n",
    "from pcdet.utils.box_utils import *\n",
    "\n",
    "\n",
    "# Testimplementierung der Klasse mit random_local_rotation_v2\n",
    "class DataAugmentor:\n",
    "    def random_local_rotation_v2(self, data_dict=None, config=None):\n",
    "        \"\"\"\n",
    "        Please check the correctness of it before using. Modified version of random_local_rotation.\n",
    "        \"\"\"\n",
    "        if data_dict is None:\n",
    "            print('DataAugmentor: random_local_rotation() called with no data_dict')\n",
    "            return partial(self.random_local_rotation_v2, config=config)\n",
    "        rot_range = config['LOCAL_ROT_ANGLE']\n",
    "        if not isinstance(rot_range, list):\n",
    "            rot_range = [-rot_range, rot_range]\n",
    "\n",
    "        num_gt_boxes = len(data_dict['gt_boxes'])\n",
    "        print('DataAugmentor: no. gt_boxes in sample: ', num_gt_boxes)\n",
    "        collision_count = 0\n",
    "       \n",
    "        if num_gt_boxes < 2: # only one bbox in gt_boxes\n",
    "            print(f'DataAugmentor: {num_gt_boxes} 3D-BB in dict entry. Skip boxes_iou3d_gpu(), applying random local rotation')\n",
    "            gt_boxes, points, noise_rot, enable = augmentor_utils.local_rotation(\n",
    "                data_dict['gt_boxes'], data_dict['points'], rot_range=rot_range)\n",
    "            print(f'DataAugmentor: random local rotation with range: {rot_range}, enabled: {enable}')\n",
    "            \n",
    "            data_dict['gt_boxes'] = gt_boxes\n",
    "            data_dict['points'] = points\n",
    "            data_dict['noise_loc_rot'] = noise_rot\n",
    "            print('DataAugmentor: random local rotation completed')\n",
    "            return data_dict\n",
    "\n",
    "        else: # several bboxes in gt_boxess\n",
    "            print(f'DataAugmentor: {num_gt_boxes} 3D-BB in dict entry. Check all IoU with boxes_iou3d_gpu()')\n",
    "            \n",
    "            gt_boxes = data_dict['gt_boxes']\n",
    "            gt_indices = list(range(gt_boxes.shape[0]))\n",
    "            iou_matrix = torch.zeros((len(gt_indices), len(gt_indices)), dtype=torch.float32).cuda()\n",
    "            \n",
    "            if gt_boxes.shape[1] == 8:\n",
    "                # (N, 8) => (N, 7) [x, y, z, dx, dy, dz, heading]\n",
    "                gt_boxes = data_dict['gt_boxes'][:, :-1]\n",
    "            else:\n",
    "                # IoU for all box pairs (excluding itself)\n",
    "                for box_a_idx, box_b_idx in itertools.combinations(gt_indices, 2):\n",
    "                    boxes_a = torch.tensor(gt_boxes[box_a_idx:box_a_idx + 1], dtype=torch.float32).cuda()\n",
    "                    boxes_b = torch.tensor(gt_boxes[box_b_idx:box_b_idx + 1], dtype=torch.float32).cuda()\n",
    "                    iou3d = boxes_iou3d_gpu(boxes_a, boxes_b)\n",
    "                    iou_matrix[box_a_idx, box_b_idx] = iou3d # save results (idx, idx)\n",
    "            \n",
    "            overlap_matrix = (iou_matrix > 0).fill_diagonal_(False) # True or False in no._boxes x no._boxes matrix\n",
    "            overlapping_indices = torch.nonzero(overlap_matrix) # box pairs (i, j)\n",
    "           \n",
    "            if overlapping_indices.numel() > 0:  # collision between 3D-BB in scene\n",
    "                collision_count += overlapping_indices.size(0)\n",
    "                print(f\"DataAugmentor: detected {collision_count} between boxes. Retrying rotation on this pair(s)...\")\n",
    "                overlapping_boxes_set = set()\n",
    "\n",
    "                for idx in overlapping_indices:\n",
    "                    box_a_idx, box_b_idx = idx[0].item(), idx[1].item()\n",
    "                    overlapping_boxes_set.add(box_a_idx)\n",
    "                    overlapping_boxes_set.add(box_b_idx)\n",
    "                \n",
    "                overlapping_boxes = np.array([gt_boxes[i] for i in overlapping_boxes_set], dtype=np.float32)\n",
    "                non_overlapping_indices = [i for i in gt_indices if i not in overlapping_boxes_set]\n",
    "                non_overlapping_boxes = np.array([gt_boxes[i] for i in non_overlapping_indices], dtype=np.float32)\n",
    "                points = data_dict['points']\n",
    "                points_in_overlap = np.empty((0, points.shape[1]))\n",
    "                \n",
    "                # extract point cloud in 3D-BB with IoU\n",
    "                for gt_box in overlapping_boxes:\n",
    "                    box_points, _ = get_points_in_box(points, gt_box)\n",
    "                    points_in_overlap = np.vstack((points_in_overlap, box_points))\n",
    "                \n",
    "                # try second rotation\n",
    "                gt_boxes, points, noise_rot, enable = augmentor_utils.local_rotation(\n",
    "                    overlapping_boxes, points_in_overlap, rot_range=rot_range)\n",
    "                print(f'DataAugmentor: local rotation applied to overlapping boxes_idx: {box_a_idx} and {box_b_idx}')\n",
    "                print(f'DataAugmentor: 2. random local rotation with range: {rot_range}, enabled: {enable}')\n",
    "                \n",
    "                # prepare type and check again IoU\n",
    "                gt_boxes = torch.tensor(gt_boxes, dtype=torch.float32).cuda() # required for boxes_iou3d_gpu\n",
    "                iou_matrix_after_rotation = torch.zeros((gt_boxes.shape[0], gt_boxes.shape[0]), dtype=torch.float32).cuda()\n",
    "                \n",
    "                for box_a_idx, box_b_idx in itertools.combinations(range(gt_boxes.shape[0]), 2):\n",
    "                    boxes_a = gt_boxes[box_a_idx:box_a_idx + 1]\n",
    "                    boxes_b = gt_boxes[box_b_idx:box_b_idx + 1]\n",
    "                    iou3d_after_rotation = boxes_iou3d_gpu(boxes_a, boxes_b)\n",
    "                    iou_matrix_after_rotation[box_a_idx, box_b_idx] = iou3d_after_rotation\n",
    "                overlap_exists = (iou3d_after_rotation.item() > 0)\n",
    "\n",
    "                if overlap_exists:\n",
    "                    print(\"DataAugmentor: overlap still exists after second rotation\")\n",
    "                    gt_boxes = gt_boxes[::2].cpu().numpy()\n",
    "                    print(f\"DataAugmentor: removed every second bbox of each overlapping pair to resolve overlap\")\n",
    "                                    \n",
    "                    all_boxes = np.vstack((gt_boxes, non_overlapping_boxes)).astype(np.float32)\n",
    "                \n",
    "                    data_dict['gt_boxes'] = all_boxes\n",
    "                    data_dict['points'] = points\n",
    "                    data_dict['noise_loc_rot'] = noise_rot\n",
    "\n",
    "                    print('DataAugmentor: local rotation on overlapping boxes completed')\n",
    "                    print(f'DataAugmentor: Total collisions detected: {collision_count}')\n",
    "                    return data_dict\n",
    "                \n",
    "                # no overlap exists\n",
    "                data_dict['gt_boxes'] = gt_boxes\n",
    "                data_dict['points'] = points\n",
    "                data_dict['noise_loc_rot'] = noise_rot\n",
    "\n",
    "                print('DataAugmentor: local rotation on overlapping boxes completed')\n",
    "                return data_dict\n",
    "            \n",
    "            else:\n",
    "                print(f'DataAugmentor: no overlaps found between the {num_gt_boxes}-BBs. Applying random local rotation')\n",
    "                gt_boxes, points, noise_rot, enable = augmentor_utils.local_rotation(\n",
    "                    data_dict['gt_boxes'], data_dict['points'], rot_range=rot_range)\n",
    "                print(f'DataAugmentor: random local rotation with range: {rot_range}, enabled: {enable}')\n",
    "                \n",
    "                data_dict['gt_boxes'] = gt_boxes\n",
    "                data_dict['points'] = points\n",
    "                data_dict['noise_loc_rot'] = noise_rot\n",
    "\n",
    "                print('DataAugmentor: random local rotation completed')\n",
    "                return data_dict\n",
    "\n",
    "\n",
    "# Konfiguration für den Test\n",
    "config = {\n",
    "    'LOCAL_ROT_ANGLE': [-0.15707963267, 0.15707963267]\n",
    "}\n",
    "\n",
    "# Test ausführen\n",
    "data_augmentor = DataAugmentor()\n",
    "data_dict = {\n",
    "    'gt_boxes': gt_boxes,\n",
    "    'points': points\n",
    "}\n",
    "print(\"GT Boxes:\", len(data_dict['gt_boxes']))\n",
    "print(\"Points:\", len(data_dict['points']))\n",
    "result = data_augmentor.random_local_rotation_v2(data_dict=data_dict, config=config)\n",
    "\n",
    "#print(\"Resulting Data Dictionary:\")\n",
    "#print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
